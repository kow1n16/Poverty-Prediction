{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\user\\google drive\\data science competitions\\predicting poverty - world bank\\xgboost-0.7-cp36-cp36m-win_amd64.whl\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost==0.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost==0.7)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost-0.7-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import model_selection, metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# data directory\n",
    "#DATA_DIR = os.path.join('C:\\\\Users\\\\User\\\\Google Drive\\\\Data Science Competitions\\\\Predicting Poverty - World Bank', 'Data', 'processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df, numeric_only=True):\n",
    "    \n",
    "        numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    # subtracy mean and divide by std\n",
    "        df[numeric.columns] = (numeric - numeric.mean()) / numeric.std()\n",
    "    \n",
    "        return df\n",
    "\n",
    "def standardize_Test(df):\n",
    "        df = df.apply(LabelEncoder().fit_transform) \n",
    "    \n",
    "        numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    # subtracy mean and divide by std\n",
    "        df[numeric.columns] = (numeric - numeric.mean()) / numeric.std()\n",
    "    \n",
    "        return df\n",
    "    \n",
    "\n",
    "def pre_process_data(df, enforce_cols=None):\n",
    "    \n",
    "        print(\"Input shape:\\t{}\".format(df.shape))\n",
    "        df = df.apply(LabelEncoder().fit_transform)  \n",
    "        enforce_cols = enforce_cols.apply(LabelEncoder().fit_transform)   \n",
    "        #df = pd.get_dummies(df)\n",
    "        print(\"After converting categoricals:\\t{}\".format(df.shape))\n",
    "        df = standardize(df)\n",
    "        enforce_cols = standardize(enforce_cols)\n",
    "        print(\"After standardization {}\".format(df.shape))\n",
    "        \n",
    "        # create dummy variables for categoricals\n",
    "    \n",
    "    \n",
    "\n",
    "    # match test set and training set columns\n",
    "        if enforce_cols is not None:\n",
    "            to_drop = np.setdiff1d(df.columns, enforce_cols.columns)\n",
    "            to_add = np.setdiff1d(enforce_cols.columns, df.columns)\n",
    "            \n",
    "            df.drop(to_drop, axis=1, inplace=True)\n",
    "            df = df.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "            df.fillna(0, inplace=True)\n",
    "    \n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_train_h = pd.read_csv('~Data\\A_hhold_train.csv')\n",
    "b_train_h = pd.read_csv('~\\Data\\B\\B_hhold_train.csv')\n",
    "c_train_h = pd.read_csv('~\\Data\\C_hhold_train.csv')\n",
    "\n",
    "a_train_i = pd.read_csv('~\\Data\\A_indiv_train.csv')\n",
    "b_train_i = pd.read_csv('~\\Data\\B_indiv_train.csv')\n",
    "c_train_i = pd.read_csv('~\\Data\\C_indiv_train.csv')\n",
    "\n",
    "a_test_h = pd.read_csv('~\\Data\\A_hhold_test.csv')\n",
    "b_test_h = pd.read_csv('~\\Data\\B_hhold_test.csv')\n",
    "c_test_h = pd.read_csv('~\\Data\\C_hhold_test.csv')\n",
    "\n",
    "a_test_i = pd.read_csv('~\\Data\\A_indiv_test.csv')\n",
    "b_test_i = pd.read_csv('~\\Data\\B_indiv_test.csv')\n",
    "c_test_i = pd.read_csv('~\\Data\\C_indiv_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country A\n",
      "Input shape:\t(37560, 387)\n",
      "After converting categoricals:\t(37560, 387)\n",
      "After standardization (37560, 387)\n",
      "\n",
      "Country B\n",
      "Input shape:\t(20252, 667)\n",
      "After converting categoricals:\t(20252, 667)\n",
      "After standardization (20252, 667)\n",
      "\n",
      "Country C\n",
      "Input shape:\t(29913, 206)\n",
      "After converting categoricals:\t(29913, 206)\n",
      "After standardization (29913, 206)\n"
     ]
    }
   ],
   "source": [
    "A_Train = pd.merge(a_train_h, a_train_i,on='id', how='outer')\n",
    "B_Train = pd.merge(b_train_h, b_train_i,on='id', how='outer')\n",
    "C_Train = pd.merge(c_train_h, c_train_i,on='id', how='outer')\n",
    "\n",
    "A_Train = A_Train.set_index('id')\n",
    "B_Train = B_Train.set_index('id')\n",
    "C_Train = C_Train.set_index('id')\n",
    "\n",
    "A_Test = pd.merge(a_test_h, a_test_i,on='id', how='outer')\n",
    "B_Test = pd.merge(b_test_h, b_test_i,on='id', how='outer')\n",
    "C_Test = pd.merge(c_test_h, c_test_i,on='id', how='outer')\n",
    "\n",
    "A_Test = A_Test.set_index('id')\n",
    "B_Test = B_Test.set_index('id')\n",
    "C_Test = C_Test.set_index('id')\n",
    "\n",
    "A_Test = standardize_Test(A_Test)\n",
    "B_Test = standardize_Test(B_Test)\n",
    "C_Test = standardize_Test(C_Test)\n",
    "\n",
    "print(\"Country A\")\n",
    "AX_Train = pre_process_data(A_Train.drop('poor_x', axis=1), enforce_cols = A_Test)\n",
    " \n",
    "print(\"\\nCountry B\")\n",
    "BX_Train = pre_process_data(B_Train.drop('poor_x', axis=1), enforce_cols = B_Test) \n",
    "\n",
    "print(\"\\nCountry C\")\n",
    "CX_Train = pre_process_data(C_Train.drop('poor_x', axis=1), enforce_cols = C_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_Train = A_Train.apply(LabelEncoder().fit_transform)\n",
    "B_Train = B_Train.apply(LabelEncoder().fit_transform)\n",
    "C_Train = C_Train.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "A_Test = A_Test.reset_index().drop_duplicates(subset='id', keep='last').set_index('id')\n",
    "B_Test = B_Test.reset_index().drop_duplicates(subset='id', keep='last').set_index('id')\n",
    "C_Test = C_Test.reset_index().drop_duplicates(subset='id', keep='last').set_index('id')\n",
    "\n",
    "ay_train = A_Train['poor_x']\n",
    "by_train = B_Train['poor_x']\n",
    "cy_train = C_Train['poor_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AX_Train = AX_Train.drop(['country_x', 'country_y', 'nKoaotpH'], axis=1)\n",
    "BXX_Train = BX_Train.drop(['HFgaiygl', 'VMvwrYds', 'country_x', 'country_y'], axis=1)\n",
    "CX_Train = CX_Train.drop(['country_x', 'country_y'], axis=1)\n",
    "\n",
    "A_Test = A_Test.drop(['country_x', 'country_y', 'nKoaotpH'], axis=1)\n",
    "B_Test = B_Test.drop(['HFgaiygl', 'VMvwrYds', 'country_x', 'country_y'], axis=1)\n",
    "C_Test = C_Test.drop(['country_x', 'country_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "def modelfit(alg, dtrain, target, dtest, useTrainCV=True, cv_folds=10, early_stopping_rounds=3):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        dtraint = xgb.DMatrix(dtrain, label=target)\n",
    "        \n",
    "        cvresult = xgb.cv(xgb_param, dtraint, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "        metrics='logloss', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "         #Fit the algorithm on the data\n",
    "        alg.fit(dtrain, target, eval_metric='logloss')\n",
    "        \n",
    "        dtrain_predictions = alg.predict(dtest)\n",
    "        dtrain_predprob = alg.predict_proba(dtest)\n",
    "        \n",
    "        log_lss = log_loss(dtrain_predictions, dtrain_predprob[:,1])\n",
    "        \n",
    "        #feat_imp =alg.feature_importances_ \n",
    "        feat_imp = pd.Series(alg._Booster.get_score()).sort_values(ascending=False)\n",
    "\n",
    "    \n",
    "        #feat_imp.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 100))\n",
    "        #plt.ylabel('Feature Importance Score')\n",
    "        return feat_imp, dtrain_predprob, log_lss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_test1 = {\n",
    " 'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    " 'n_estimators': list(range(100,500,100)), \n",
    " 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    " #'min_child_weight' : list(range(30,40,1))\n",
    "# 'colsample_bytree':[i/100.0 for i in range(2,22)]\n",
    " #'reg_lambda':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    " #'gamma':[i/100.0 for i in range(11,11)]\n",
    " #'subsample':[1, 2, 3, 4, 5]\n",
    " #'max_delta_step' : [0, 1,2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "  #'reg_alpha': [i/100.0 for i in range(1,10)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=10, verbose=10)\n",
    "#print(gsearch1)\n",
    "#n_estimators=600, reg_alpha=0.2, gamma=1.9, colsample_bytree=0.3, min_child_weight=27,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 360 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 35.0min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 51.9min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 76.0min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed: 89.9min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed: 109.7min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed: 126.7min\n"
     ]
    }
   ],
   "source": [
    "gsearch1.fit(AX_Train,ay_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_test2 = {\n",
    "#'learning_rate': [i/100 for i in range(0,10)],\n",
    "# 'n_estimators': list(range(1000,1500,100)), \n",
    " #'max_depth': list(range(1,9,1)),\n",
    " 'min_child_weight' : list(range(1,10,1)),\n",
    " #'colsample_bylevel':[0.5, 1]\n",
    " #'colsample_bytree':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    " 'gamma': [i/100.0 for i in range(10,20)],\n",
    " #'subsample':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    " #'max_delta_step': [0, 1, 2, 4, 5, 6, 7, 8, 9, 10],\n",
    " 'reg_alpha': [i/1000.0 for i in range(20,100, 10)]  \n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(gamma=0.1, reg_alpha=0.02, nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=10, verbose=10)\n",
    "#print(gsearch1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsearch2.fit(BXX_Train,by_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alg1 = XGBClassifier(n_estimators=600, max_depth=3, learning_rate=0.1, reg_alpha = 0.2, colsample_bytree =0.2, gamma=1.9, min_child_weight=27)\n",
    "#alg23 = XGBClassifier(n_estimators=100, reg_alpha=0.08, min_child_weight=18, gamma=0.1, max_delta_step=2, colsample_bytree = 0.4)\n",
    "#alg24 = XGBClassifier()\n",
    "#alg23 = XGBClassifier(gamma=0.1, reg_alpha=0.02, min_child_weight=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "feat_a, p_a, log_loss_a = modelfit(alg1, AX_Train, ay_train, A_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_b, p_b, log_loss_b = modelfit(alg23, BXX_Train, by_train, B_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_c, p_c, log_loss_c = modelfit(alg24, CX_Train, cy_train, C_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0981484258898\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    " \n",
    "print(statistics.mean([log_loss_a, log_loss_b, log_loss_c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_country_sub(preds, test_feat, country):\n",
    "    # make sure we code the country correctly\n",
    "    country_codes = ['A', 'B', 'C']\n",
    "    \n",
    "    # get just the poor probabilities\n",
    "    country_sub = pd.DataFrame(data=preds[:, 1],  # proba p=1\n",
    "                               columns=['poor'], \n",
    "                               index=test_feat.index)\n",
    "\n",
    "    \n",
    "    # add the country code for joining later\n",
    "    country_sub[\"country\"] = country\n",
    "    return country_sub[[\"country\", \"poor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_sub = make_country_sub(p_a, A_Test, 'A')\n",
    "b_sub = make_country_sub(p_b, B_Test, 'B')\n",
    "c_sub = make_country_sub(p_c, C_Test, 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>poor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>A</td>\n",
       "      <td>0.962800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41249</th>\n",
       "      <td>A</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16205</th>\n",
       "      <td>A</td>\n",
       "      <td>0.795557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97501</th>\n",
       "      <td>A</td>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67756</th>\n",
       "      <td>A</td>\n",
       "      <td>0.978803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country      poor\n",
       "id                     \n",
       "418         A  0.962800\n",
       "41249       A  0.000832\n",
       "16205       A  0.795557\n",
       "97501       A  0.000570\n",
       "67756       A  0.978803"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>poor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9135</th>\n",
       "      <td>B</td>\n",
       "      <td>0.022004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>B</td>\n",
       "      <td>0.029178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29085</th>\n",
       "      <td>B</td>\n",
       "      <td>0.019645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55442</th>\n",
       "      <td>B</td>\n",
       "      <td>0.031494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29281</th>\n",
       "      <td>B</td>\n",
       "      <td>0.013645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      country      poor\n",
       "id                     \n",
       "9135        B  0.022004\n",
       "117         B  0.029178\n",
       "29085       B  0.019645\n",
       "55442       B  0.031494\n",
       "29281       B  0.013645"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([a_sub, b_sub, c_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
